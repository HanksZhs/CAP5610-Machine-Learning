{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "# assign to first GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#VRAM memory on-demand usage(prevent Keras takes all memory at the beginning)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True   \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (50000, 32, 32, 3)\n",
      "x_train shape: (40000, 32, 32, 3)\n",
      "x_val shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "num_predictions = 20\n",
    "batch_size = 64\n",
    "\n",
    "(x_main, y_main), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('x shape:', x_main.shape)\n",
    "x_train=x_main[:40000]\n",
    "y_train=y_main[:40000]\n",
    "print('x_train shape:', x_train.shape)\n",
    "x_val=x_main[40000:]\n",
    "y_val=y_main[40000:]\n",
    "print('x_val shape:', x_val.shape)\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    elif epoch > 100:\n",
    "        lrate = 0.0003        \n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 1.9530 - acc: 0.4106 - val_loss: 1.6525 - val_acc: 0.4808\n",
      "Epoch 2/125\n",
      "625/625 [==============================] - 14s 23ms/step - loss: 1.4704 - acc: 0.5595 - val_loss: 1.2241 - val_acc: 0.6143\n",
      "Epoch 3/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 1.2844 - acc: 0.6208 - val_loss: 1.1017 - val_acc: 0.6450\n",
      "Epoch 4/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 1.1841 - acc: 0.6580 - val_loss: 1.0701 - val_acc: 0.6868\n",
      "Epoch 5/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 1.1210 - acc: 0.6838 - val_loss: 0.9826 - val_acc: 0.7161\n",
      "Epoch 6/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 1.0778 - acc: 0.7030 - val_loss: 0.9592 - val_acc: 0.7019\n",
      "Epoch 7/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 1.0616 - acc: 0.7118 - val_loss: 0.9918 - val_acc: 0.7231\n",
      "Epoch 8/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 1.0250 - acc: 0.7253 - val_loss: 1.0567 - val_acc: 0.7058\n",
      "Epoch 9/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 1.0069 - acc: 0.7349 - val_loss: 0.8440 - val_acc: 0.7650\n",
      "Epoch 10/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9881 - acc: 0.7390 - val_loss: 1.3204 - val_acc: 0.6435\n",
      "Epoch 11/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9640 - acc: 0.7495 - val_loss: 0.8839 - val_acc: 0.7663\n",
      "Epoch 12/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9530 - acc: 0.7563 - val_loss: 0.8579 - val_acc: 0.7703\n",
      "Epoch 13/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9602 - acc: 0.7600 - val_loss: 0.8153 - val_acc: 0.7902\n",
      "Epoch 14/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9361 - acc: 0.7657 - val_loss: 0.8023 - val_acc: 0.7769\n",
      "Epoch 15/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9338 - acc: 0.7662 - val_loss: 0.8663 - val_acc: 0.7716\n",
      "Epoch 16/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9110 - acc: 0.7713 - val_loss: 0.8015 - val_acc: 0.7907\n",
      "Epoch 17/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9163 - acc: 0.7747 - val_loss: 0.9449 - val_acc: 0.7473\n",
      "Epoch 18/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9140 - acc: 0.7780 - val_loss: 0.8790 - val_acc: 0.7792\n",
      "Epoch 19/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9064 - acc: 0.7762 - val_loss: 1.0874 - val_acc: 0.7082\n",
      "Epoch 20/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9082 - acc: 0.7794 - val_loss: 0.7492 - val_acc: 0.8074\n",
      "Epoch 21/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8990 - acc: 0.7862 - val_loss: 0.9951 - val_acc: 0.7737\n",
      "Epoch 22/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8866 - acc: 0.7849 - val_loss: 0.8317 - val_acc: 0.7899\n",
      "Epoch 23/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8757 - acc: 0.7869 - val_loss: 0.8272 - val_acc: 0.7843\n",
      "Epoch 24/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8841 - acc: 0.7923 - val_loss: 0.8959 - val_acc: 0.7789\n",
      "Epoch 25/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9613 - acc: 0.7855 - val_loss: 0.8458 - val_acc: 0.7786\n",
      "Epoch 26/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9453 - acc: 0.7876 - val_loss: 0.8843 - val_acc: 0.7932\n",
      "Epoch 27/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9139 - acc: 0.7923 - val_loss: 0.9614 - val_acc: 0.7698\n",
      "Epoch 28/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8924 - acc: 0.7966 - val_loss: 0.8362 - val_acc: 0.7847\n",
      "Epoch 29/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9139 - acc: 0.7959 - val_loss: 0.7844 - val_acc: 0.8114\n",
      "Epoch 30/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9104 - acc: 0.8003 - val_loss: 0.7685 - val_acc: 0.8156\n",
      "Epoch 31/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.9270 - acc: 0.7988 - val_loss: 0.8658 - val_acc: 0.7895\n",
      "Epoch 32/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8829 - acc: 0.8032 - val_loss: 0.8496 - val_acc: 0.7897\n",
      "Epoch 33/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8920 - acc: 0.8022 - val_loss: 0.7608 - val_acc: 0.8146\n",
      "Epoch 34/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8608 - acc: 0.8030 - val_loss: 0.8982 - val_acc: 0.7823\n",
      "Epoch 35/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8668 - acc: 0.8056 - val_loss: 0.7547 - val_acc: 0.8180\n",
      "Epoch 36/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8735 - acc: 0.8075 - val_loss: 0.7674 - val_acc: 0.8131\n",
      "Epoch 37/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8719 - acc: 0.8072 - val_loss: 0.8044 - val_acc: 0.7930\n",
      "Epoch 38/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8872 - acc: 0.8033 - val_loss: 0.7367 - val_acc: 0.8247\n",
      "Epoch 39/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8623 - acc: 0.8078 - val_loss: 0.7296 - val_acc: 0.8274\n",
      "Epoch 40/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8626 - acc: 0.8112 - val_loss: 0.8441 - val_acc: 0.7927\n",
      "Epoch 41/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8568 - acc: 0.8091 - val_loss: 0.7694 - val_acc: 0.8250\n",
      "Epoch 42/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8513 - acc: 0.8110 - val_loss: 0.7997 - val_acc: 0.8114\n",
      "Epoch 43/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8485 - acc: 0.8124 - val_loss: 0.7625 - val_acc: 0.8291\n",
      "Epoch 44/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8508 - acc: 0.8127 - val_loss: 0.8596 - val_acc: 0.8041\n",
      "Epoch 45/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8632 - acc: 0.8109 - val_loss: 0.7398 - val_acc: 0.8194\n",
      "Epoch 46/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8573 - acc: 0.8131 - val_loss: 0.6826 - val_acc: 0.8498\n",
      "Epoch 47/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8635 - acc: 0.8113 - val_loss: 1.2254 - val_acc: 0.7921\n",
      "Epoch 48/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8298 - acc: 0.8139 - val_loss: 0.7823 - val_acc: 0.8101\n",
      "Epoch 49/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8068 - acc: 0.8172 - val_loss: 0.7511 - val_acc: 0.8245\n",
      "Epoch 50/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8082 - acc: 0.8172 - val_loss: 0.8167 - val_acc: 0.8148\n",
      "Epoch 51/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8047 - acc: 0.8168 - val_loss: 0.7772 - val_acc: 0.8165\n",
      "Epoch 52/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8105 - acc: 0.8172 - val_loss: 1.0094 - val_acc: 0.7634\n",
      "Epoch 53/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8016 - acc: 0.8190 - val_loss: 0.7344 - val_acc: 0.8281\n",
      "Epoch 54/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7943 - acc: 0.8180 - val_loss: 0.7105 - val_acc: 0.8374\n",
      "Epoch 55/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7995 - acc: 0.8190 - val_loss: 0.7084 - val_acc: 0.8329\n",
      "Epoch 56/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7887 - acc: 0.8252 - val_loss: 0.7536 - val_acc: 0.8178\n",
      "Epoch 57/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8089 - acc: 0.8179 - val_loss: 0.7564 - val_acc: 0.8065\n",
      "Epoch 58/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7848 - acc: 0.8201 - val_loss: 0.7095 - val_acc: 0.8328\n",
      "Epoch 59/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.8050 - acc: 0.8206 - val_loss: 0.8150 - val_acc: 0.8077\n",
      "Epoch 60/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7751 - acc: 0.8208 - val_loss: 0.8333 - val_acc: 0.7949\n",
      "Epoch 61/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7637 - acc: 0.8254 - val_loss: 0.8532 - val_acc: 0.8142\n",
      "Epoch 62/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7417 - acc: 0.8262 - val_loss: 0.7192 - val_acc: 0.8322\n",
      "Epoch 63/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7540 - acc: 0.8237 - val_loss: 0.6974 - val_acc: 0.8414\n",
      "Epoch 64/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7358 - acc: 0.8242 - val_loss: 0.7396 - val_acc: 0.8258\n",
      "Epoch 65/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7418 - acc: 0.8249 - val_loss: 0.8162 - val_acc: 0.7962\n",
      "Epoch 66/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7311 - acc: 0.8284 - val_loss: 0.7375 - val_acc: 0.8336\n",
      "Epoch 67/125\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7287 - acc: 0.8256 - val_loss: 0.8054 - val_acc: 0.8038\n",
      "Epoch 68/125\n",
      "377/625 [=================>............] - ETA: 5s - loss: 0.7024 - acc: 0.8269"
     ]
    }
   ],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    "\n",
    "#training\n",
    "\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
    "                    verbose=1,validation_data=(x_val,y_val),callbacks=[LearningRateScheduler(lr_schedule)])\n",
    "\n",
    "#save to disk\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('model.h5')    \n",
    "\n",
    "#testing\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
