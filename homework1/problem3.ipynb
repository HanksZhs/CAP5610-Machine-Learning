{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "from keras.datasets import mnist \n",
    "from keras.utils import np_utils\n",
    "\n",
    "# the data, shuffled and split between train and test sets \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "input_dim = 784 #28*28 \n",
    "X_train = X_train.reshape(60000, input_dim) \n",
    "X_test = X_test.reshape(10000, input_dim) \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train /= 255 \n",
    "X_test /= 255\n",
    "nb_classes = 10 \n",
    "m=X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, nb_classes) \n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassModel:\n",
    "    def __init__(self, n_class=None, weights=None, bias=None):\n",
    "        self.n_class = n_class\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.weights_history = []\n",
    "    \n",
    "    # softmax activation\n",
    "    def softmax(self, z):\n",
    "        z_exp = np.exp(z - np.max(z, -1, keepdims=True))\n",
    "        return z_exp / np.sum(z_exp, -1, keepdims=True )\n",
    "    \n",
    "    \n",
    "    # categorical cross entropy\n",
    "    def cce(self, a, y):\n",
    "        return -np.sum(y * np.log(a), axis=-1)\n",
    "        \n",
    "        \n",
    "    def fit(self, x, y, epochs=1, test_x=None, test_y=None, lr=0.01, batch_size=4, verbose=0):\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        if self.n_class is None:\n",
    "            self.n_class = y.shape[1]\n",
    "        if self.weights is None:\n",
    "            self.weights = np.zeros((x.shape[1], self.n_class))\n",
    "            #self.weights = np.random.randn(x.shape[1], self.n_class)\n",
    "        if self.bias is None:\n",
    "            self.bias = np.random.randn(1, self.n_class)\n",
    "        \n",
    "        history = {\n",
    "            'loss': []\n",
    "        }\n",
    "\n",
    "        # for each epoch/iteration\n",
    "        for epoch in range(epochs):\n",
    "            if verbose > 0:\n",
    "                print(\"Epoch {}/{}\".format(epoch+1,epochs))\n",
    "                \n",
    "            shuffled_indices = np.random.permutation(m)\n",
    "            x_shuffled = x[shuffled_indices]\n",
    "            y_shuffled = y[shuffled_indices]\n",
    "            loss = []\n",
    "            for i in range(0, x.shape[0], batch_size):\n",
    "                xi = x_shuffled[i:i+batch_size]\n",
    "                yi = y_shuffled[i:i+batch_size]\n",
    "                z = xi.dot(self.weights) + self.bias\n",
    "                a = self.softmax(z)\n",
    "\n",
    "                gradient = a - yi\n",
    "                \n",
    "                self.weights = self.weights - lr * (gradient.T @ xi).T/batch_size\n",
    "                self.bias = self.bias - lr * gradient.mean(axis=0)\n",
    "                \n",
    "                if i % (x.shape[0]/30) == 0:\n",
    "                    self.weights_history += [self.softmax(self.weights)]\n",
    "\n",
    "            history['loss'] += [self.cce(self.predict(x_shuffled), y_shuffled).mean()]\n",
    "\n",
    "            if verbose > 0:\n",
    "                print(\"Loss: {}\\n\".format(history['loss'][-1]))\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.softmax(x.dot(self.weights) + self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Loss: 0.33018503051402487\n",
      "\n",
      "Epoch 2/10\n",
      "Loss: 0.3078837961499815\n",
      "\n",
      "Epoch 3/10\n",
      "Loss: 0.2926140724086701\n",
      "\n",
      "Epoch 4/10\n",
      "Loss: 0.28232766804313464\n",
      "\n",
      "Epoch 5/10\n",
      "Loss: 0.2813970795655232\n",
      "\n",
      "Epoch 6/10\n",
      "Loss: 0.2742913880393783\n",
      "\n",
      "Epoch 7/10\n",
      "Loss: 0.27113971251835284\n",
      "\n",
      "Epoch 8/10\n",
      "Loss: 0.2704659185363247\n",
      "\n",
      "Epoch 9/10\n",
      "Loss: 0.2655948539326872\n",
      "\n",
      "Epoch 10/10\n",
      "Loss: 0.2629228773805314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MulticlassModel()\n",
    "history = model.fit(X_train, Y_train, epochs=10, verbose=1, lr=0.01, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(y_predic,y_origin):\n",
    "    temp=np.zeros_like(y_origin)\n",
    "    for i in range(y_origin.shape[0]):\n",
    "        if np.argmax(y_predic[i])==y_origin[i]:\n",
    "            temp[i]=0\n",
    "        else:\n",
    "            temp[i]=1\n",
    "        \n",
    "    return (100.0 - np.mean(temp*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  92.78666666666666\n",
      "Accuarcy Test:   92.43\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "print(\"Accuracy Train: \",get_acc(pred_train,y_train))\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"Accuarcy Test:  \",get_acc(pred_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
