{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_images.shape)\n",
    "train_images=train_images.reshape(train_images.shape[0],train_images.shape[1]*train_images.shape[2])\n",
    "print(train_images.shape)\n",
    "test_images=test_images.reshape(test_images.shape[0],test_images.shape[1]*test_images.shape[2])\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training img and test img\n",
    "train_images_normalised = train_images/255.0\n",
    "test_images_normalised = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(784, 10000)\n",
      "(1, 60000)\n",
      "(1, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Get the transpose of images and labels\n",
    "train_img_tr = train_images_normalised.transpose()\n",
    "test_img_tr = test_images_normalised.transpose()\n",
    "train_label_tr = train_labels.reshape(1,train_labels.shape[0])\n",
    "test_label_tr = test_labels.reshape(1,test_labels.shape[0])\n",
    "print(train_img_tr.shape)\n",
    "print(test_img_tr.shape)\n",
    "print(train_label_tr.shape)\n",
    "print(test_label_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has dimensions equal to 60000\n",
      "The test set has dimensions equal to 10000\n"
     ]
    }
   ],
   "source": [
    "dim_train = train_img_tr.shape[1]\n",
    "dim_test = test_img_tr.shape[1]\n",
    "print(\"The training dataset has dimensions equal to\", dim_train)\n",
    "print(\"The test set has dimensions equal to\", dim_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the labels for each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_label(label,target):\n",
    "    label_copy=label.copy()\n",
    "    for i in range (0,label.shape[1]):\n",
    "        if label[0][i]==target:\n",
    "            label_copy[0][i]=1\n",
    "        else:\n",
    "            label_copy[0][i]=0\n",
    "    return label_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o: [2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7]\n",
      "9: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "8: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "7: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "6: [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "5: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "4: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      "3: [0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "2: [1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "1: [0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "0: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "train_label_shifted_9 = train_label_tr//9\n",
    "test_label_shifted_9 = test_label_tr//9\n",
    "train_label_shifted_8 = shifted_label(train_label_tr,8)\n",
    "test_label_shifted_8 = shifted_label(test_label_tr,8)\n",
    "train_label_shifted_7 = shifted_label(train_label_tr,7)\n",
    "test_label_shifted_7 = shifted_label(test_label_tr,7)\n",
    "train_label_shifted_6 = shifted_label(train_label_tr,6)\n",
    "test_label_shifted_6 = shifted_label(test_label_tr,6)\n",
    "train_label_shifted_5 = shifted_label(train_label_tr,5)\n",
    "test_label_shifted_5 = shifted_label(test_label_tr,5)\n",
    "train_label_shifted_4 = shifted_label(train_label_tr,4)\n",
    "test_label_shifted_4 = shifted_label(test_label_tr,4)\n",
    "train_label_shifted_3 = shifted_label(train_label_tr,3)\n",
    "test_label_shifted_3 = shifted_label(test_label_tr,3)\n",
    "train_label_shifted_2 = shifted_label(train_label_tr,2)\n",
    "test_label_shifted_2 = shifted_label(test_label_tr,2)\n",
    "train_label_shifted_1 = shifted_label(train_label_tr,1)\n",
    "test_label_shifted_1 = shifted_label(test_label_tr,1)\n",
    "train_label_shifted_0 = shifted_label(train_label_tr,0)\n",
    "test_label_shifted_0 = shifted_label(test_label_tr,0)\n",
    "\n",
    "print(\"o:\",train_label_tr[0][5:30])\n",
    "print(\"9:\",train_label_shifted_9[0][5:30])\n",
    "print(\"8:\",train_label_shifted_8[0][5:30])\n",
    "print(\"7:\",train_label_shifted_7[0][5:30])\n",
    "print(\"6:\",train_label_shifted_6[0][5:30])\n",
    "print(\"5:\",train_label_shifted_5[0][5:30])\n",
    "print(\"4:\",train_label_shifted_4[0][5:30])\n",
    "print(\"3:\",train_label_shifted_3[0][5:30])\n",
    "print(\"2:\",train_label_shifted_2[0][5:30])\n",
    "print(\"1:\",train_label_shifted_1[0][5:30])\n",
    "print(\"0:\",train_label_shifted_0[0][5:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid activation\n",
    "def sigmoid(z):\n",
    "    s = 1.0 / (1.0 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weight and bias\n",
    "def initialize(dim):\n",
    "    #w = np.zeros((dim,1))\n",
    "    w= np.random.rand(dim,1)*0.1\n",
    "    b = 0   \n",
    "    # assert (w.shape == (dim,1))\n",
    "    # assert (isinstance(b, float) or isinstance(b,int))\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# propagate\n",
    "def propagate(w, b, X, Y):\n",
    "   \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    z = np.dot(w.T,X)+b#prediction Y^\n",
    "    A = sigmoid(z)\n",
    "    cost = 1.0/m*0.5*np.dot((A-Y),(A-Y).T)\n",
    "    \n",
    "    dw=1.0/m* np.dot(X,(np.dot((A-Y),A.T)*(1-A)).T)\n",
    "    db=1.0/m*np.sum(np.dot(np.dot((A-Y),A.T),(1-A)))\n",
    "    \n",
    "    assert (dw.shape == w.shape)\n",
    "    assert (db.dtype == float)\n",
    "    \n",
    "    cost = np.squeeze(cost)\n",
    "    assert (cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw, \n",
    "             \"db\":db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Loss (iteration %i) = %f\" %(i, cost))\n",
    "            \n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    params = {\"w\": w, \"b\": b}\n",
    "        \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (w, b, X):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0],1)\n",
    "    A = sigmoid (np.dot(w.T, X)+b)\n",
    "    for i in range(A.shape[1]):\n",
    "        if (A[:,i] > 0.5): \n",
    "            Y_prediction[:, i] = 1\n",
    "        elif (A[:,i] <= 0.5):\n",
    "            Y_prediction[:, i] = 0\n",
    "            \n",
    "    assert (Y_prediction.shape == (1,m))\n",
    "    \n",
    "    return Y_prediction,A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model (X_train, Y_train, X_test, Y_test, num_iterations = 1000, learning_rate = 0.5, print_cost = False):\n",
    "    \n",
    "    w, b = initialize(X_train.shape[0])\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    Y_prediction_test,test_prob = predict (w, b, X_test)\n",
    "    Y_prediction_train,train_prob = predict (w, b, X_train)\n",
    "    \n",
    "    train_accuracy = 100.0 - np.mean(np.abs(Y_prediction_train-Y_train)*100.0)\n",
    "    test_accuracy = 100.0 - np.mean(np.abs(Y_prediction_test-Y_test)*100.0)\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "        \"Y_prediction_test\": Y_prediction_test,\n",
    "        \"Y_prediction_train\": Y_prediction_train,\n",
    "         \"w\": w,\n",
    "         \"b\": b,\n",
    "         \"learning_rate\": learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    print (\"Accuarcy Test: \",  test_accuracy)\n",
    "    print (\"Accuracy Train: \", train_accuracy)\n",
    "    \n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Running model for 9----------\n",
      "Loss (iteration 0) = 0.434424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss (iteration 100) = 0.049575\n",
      "Accuarcy Test:  89.91\n",
      "Accuracy Train:  90.08500000000001\n",
      "----------Running model for 8----------\n",
      "Loss (iteration 0) = 0.434015\n",
      "Loss (iteration 100) = 0.048758\n",
      "Accuarcy Test:  90.26\n",
      "Accuracy Train:  90.24833333333333\n",
      "----------Running model for 7----------\n",
      "Loss (iteration 0) = 0.432417\n",
      "Loss (iteration 100) = 0.052208\n",
      "Accuarcy Test:  89.72\n",
      "Accuracy Train:  89.55833333333334\n",
      "----------Running model for 6----------\n",
      "Loss (iteration 0) = 0.434964\n",
      "Loss (iteration 100) = 0.049317\n",
      "Accuarcy Test:  90.42\n",
      "Accuracy Train:  90.13666666666667\n",
      "----------Running model for 5----------\n",
      "Loss (iteration 0) = 0.440143\n",
      "Loss (iteration 100) = 0.045175\n",
      "Accuarcy Test:  91.08\n",
      "Accuracy Train:  90.965\n",
      "----------Running model for 4----------\n",
      "Loss (iteration 0) = 0.436075\n",
      "Loss (iteration 100) = 0.048683\n",
      "Accuarcy Test:  90.18\n",
      "Accuracy Train:  90.26333333333334\n",
      "----------Running model for 3----------\n",
      "Loss (iteration 0) = 0.434701\n",
      "Loss (iteration 100) = 0.051092\n",
      "Accuarcy Test:  89.9\n",
      "Accuracy Train:  89.78166666666667\n",
      "----------Running model for 2----------\n",
      "Loss (iteration 0) = 0.435003\n",
      "Loss (iteration 100) = 0.049650\n",
      "Accuarcy Test:  89.68\n",
      "Accuracy Train:  90.07\n",
      "----------Running model for 1----------\n",
      "Loss (iteration 0) = 0.432227\n",
      "Loss (iteration 100) = 0.056183\n",
      "Accuarcy Test:  88.65\n",
      "Accuracy Train:  88.76333333333334\n",
      "----------Running model for 0----------\n",
      "Loss (iteration 0) = 0.435156\n",
      "Loss (iteration 100) = 0.049358\n",
      "Accuarcy Test:  90.2\n",
      "Accuracy Train:  90.12833333333333\n"
     ]
    }
   ],
   "source": [
    "#Running model for each digit\n",
    "Xtrain = train_img_tr\n",
    "ytrain = train_label_shifted_9\n",
    "Xtest = test_img_tr\n",
    "ytest = test_label_shifted_9\n",
    "print(\"----------Running model for 9----------\")\n",
    "d9 = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 200, \n",
    "           learning_rate = 0.1, \n",
    "           print_cost = True)\n",
    "\n",
    "ytrain = train_label_shifted_8\n",
    "ytest = test_label_shifted_8\n",
    "print(\"----------Running model for 8----------\")\n",
    "d8 = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 200, \n",
    "           learning_rate = 0.1, \n",
    "           print_cost = True)\n",
    "\n",
    "ytrain = train_label_shifted_7\n",
    "ytest = test_label_shifted_7\n",
    "print(\"----------Running model for 7----------\")\n",
    "d7 = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 200, \n",
    "           learning_rate = 0.1, \n",
    "           print_cost = True)\n",
    "\n",
    "ytrain = train_label_shifted_6\n",
    "ytest = test_label_shifted_6\n",
    "print(\"----------Running model for 6----------\")\n",
    "d6 = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 200, \n",
    "           learning_rate = 0.1, \n",
    "           print_cost = True)\n",
    "\n",
    "ytrain = train_label_shifted_5\n",
    "ytest = test_label_shifted_5\n",
    "print(\"----------Running model for 5----------\")\n",
    "d5 = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 200, \n",
    "           learning_rate = 0.1, \n",
    "           print_cost = True)\n",
    "\n",
    "ytrain = train_label_shifted_4\n",
    "ytest = test_label_shifted_4\n",
    "print(\"----------Running model for 4----------\")\n",
    "d4 = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 200, \n",
    "           learning_rate = 0.1, \n",
    "           print_cost = True)\n",
    "\n",
    "ytrain = train_label_shifted_3\n",
    "ytest = test_label_shifted_3\n",
    "print(\"----------Running model for 3----------\")\n",
    "d3 = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 200, \n",
    "           learning_rate = 0.1, \n",
    "           print_cost = True)\n",
    "\n",
    "ytrain = train_label_shifted_2\n",
    "ytest = test_label_shifted_2\n",
    "print(\"----------Running model for 2----------\")\n",
    "d2 = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 200, \n",
    "           learning_rate = 0.1, \n",
    "           print_cost = True)\n",
    "\n",
    "ytrain = train_label_shifted_1\n",
    "ytest = test_label_shifted_1\n",
    "print(\"----------Running model for 1----------\")\n",
    "d1 = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 200, \n",
    "           learning_rate = 0.1, \n",
    "           print_cost = True)\n",
    "\n",
    "ytrain = train_label_shifted_0\n",
    "ytest = test_label_shifted_0\n",
    "print(\"----------Running model for 0----------\")\n",
    "d0 = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 200, \n",
    "           learning_rate = 0.1, \n",
    "           print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a'(a derivative) almost euqal to 0 when z is very small or large, causing the neuron saturated, in this problem, this situatin is meant to happend, hence using the binary cross entropy loss function can significantly improve the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this digit most likely to be: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Use only one samples to test the result\n",
    "try_set=test_img_tr[:,5]\n",
    "# print(try_set.shape)\n",
    "try_set=try_set.reshape(try_set.shape[0],1)\n",
    "# print(try_set.shape)\n",
    "res_prob=[]\n",
    "Y_0 ,prob_0=predict (d0[\"w\"], d0[\"b\"], try_set)\n",
    "Y_1 ,prob_1=predict (d1[\"w\"], d1[\"b\"], try_set)\n",
    "Y_2 ,prob_2=predict (d2[\"w\"], d2[\"b\"], try_set)\n",
    "Y_3 ,prob_3=predict (d3[\"w\"], d3[\"b\"], try_set)\n",
    "Y_4 ,prob_4=predict (d4[\"w\"], d4[\"b\"], try_set)\n",
    "Y_5 ,prob_5=predict (d5[\"w\"], d5[\"b\"], try_set)\n",
    "Y_6 ,prob_6=predict (d6[\"w\"], d6[\"b\"], try_set)\n",
    "Y_7 ,prob_7=predict (d7[\"w\"], d7[\"b\"], try_set)\n",
    "Y_8 ,prob_8=predict (d8[\"w\"], d8[\"b\"], try_set)\n",
    "Y_9,prob_9=predict (d9[\"w\"], d9[\"b\"], try_set)\n",
    "res_prob.append(prob_0)\n",
    "res_prob.append(prob_1)\n",
    "res_prob.append(prob_2)\n",
    "res_prob.append(prob_3)\n",
    "res_prob.append(prob_4)\n",
    "res_prob.append(prob_5)\n",
    "res_prob.append(prob_6)\n",
    "res_prob.append(prob_7)\n",
    "res_prob.append(prob_8)\n",
    "res_prob.append(prob_9)\n",
    "print(\"this digit most likely to be:\",np.argmax(res_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABQlJREFUeJzt3bFqVFsYgNGMiRIrLWzVyk4QBG0Eu7RaW9gKsfIh1BfwMQQbK0tF0liKnYWFlsFOkBRzH+Bmdrxz7ozJfGuV+Tn7BPRzg3vOmdl8Pt8CNt+5v/0LAOshdogQO0SIHSLEDhE7a76f//qH1Zsd90M7O0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDhNghYudv/wJstrdv3y6cPXjwYHjtq1evhvP9/f3hfHt7ezivsbNDhNghQuwQIXaIEDtEiB0ixA4Rs/l8vs77rfVmrN7h4eFwfuvWrYWzHz9+TLr3r1+/hvOLFy9OWv8Mmx33Qzs7RIgdIsQOEWKHCLFDhNghwiOuTPLhw4fhfMrx2qNHj4bz3d3dpdcusrNDhNghQuwQIXaIEDtEiB0ixA4RztkZ+v3793D+/Pnzld378ePHw/lsduyTnCxgZ4cIsUOE2CFC7BAhdogQO0SIHSK8SpqhT58+Ded3795deu2dnfHHPI6OjpZeO86rpKFM7BAhdogQO0SIHSLEDhFihwjPszP05s2bla29t7e3srX5Nzs7RIgdIsQOEWKHCLFDhNghQuwQ4Zydoffv30+6/sKFCwtnL1++nLQ2/42dHSLEDhFihwixQ4TYIULsEOFV0nEHBwfD+b179yatf/ny5YWznz9/TlqbhbxKGsrEDhFihwixQ4TYIULsECF2iPCIa9xJX8k81f7+/krX58/Z2SFC7BAhdogQO0SIHSLEDhFihwjn7HFTz9lHz6tvbW1tPX36dNL6/H/s7BAhdogQO0SIHSLEDhFihwixQ4T3xm+4jx8/Duf3798fzk/6+3H9+vXh/Nu3b8M5K+G98VAmdogQO0SIHSLEDhFihwixQ4Tn2Tfc4eHhcD71cxZ7e3uTrmd97OwQIXaIEDtEiB0ixA4RYocIR28b7vXr15OuP+lV0U+ePJm0PutjZ4cIsUOE2CFC7BAhdogQO0SIHSK8SnoDfP/+feHs2rVrw2tP+vO/efPmcP758+fhnL/Cq6ShTOwQIXaIEDtEiB0ixA4RYocIz7NvgIODg4WzqZ+jePjw4aTrOT3s7BAhdogQO0SIHSLEDhFihwixQ4Rz9g1w0tcyj1y5cmU4f/bs2dJrc7rY2SFC7BAhdogQO0SIHSLEDhGO3jbAu3fvlr726tWrw/mlS5eWXpvTxc4OEWKHCLFDhNghQuwQIXaIEDtEOGc/A46Ojobzr1+/Lr327u7ucH7+/Pml1+Z0sbNDhNghQuwQIXaIEDtEiB0ixA4RztnPgHPnxv8m37lzZ+Hsy5cvw2tv3Lix1O/E2WNnhwixQ4TYIULsECF2iBA7RIgdIpyznwHb29vD+YsXLxbOZrPZ8Nrbt28v9Ttx9tjZIULsECF2iBA7RIgdIsQOEWKHiNl8Pl/n/dZ6M4g69sMVdnaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDxLq/snn8/cHAytjZIULsECF2iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLEDhFih4h/AOEUh3BOM3oWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def plot_digit(some_digit):\n",
    "    \n",
    "    some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "    plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "plot_digit(try_set)\n",
    "print(test_label_tr[0][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the result using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten_digit(data):\n",
    "    res_prob=[]\n",
    "    Y_0 ,prob_0=predict (d0[\"w\"], d0[\"b\"], data)\n",
    "    Y_1 ,prob_1=predict (d1[\"w\"], d1[\"b\"], data)\n",
    "    Y_2 ,prob_2=predict (d2[\"w\"], d2[\"b\"], data)\n",
    "    Y_3 ,prob_3=predict (d3[\"w\"], d3[\"b\"], data)\n",
    "    Y_4 ,prob_4=predict (d4[\"w\"], d4[\"b\"], data)\n",
    "    Y_5 ,prob_5=predict (d5[\"w\"], d5[\"b\"], data)\n",
    "    Y_6 ,prob_6=predict (d6[\"w\"], d6[\"b\"], data)\n",
    "    Y_7 ,prob_7=predict (d7[\"w\"], d7[\"b\"], data)\n",
    "    Y_8 ,prob_8=predict (d8[\"w\"], d8[\"b\"], data)\n",
    "    Y_9 ,prob_9=predict (d9[\"w\"], d9[\"b\"], data)\n",
    "    res_prob.append(prob_0)\n",
    "    res_prob.append(prob_1)\n",
    "    res_prob.append(prob_2)\n",
    "    res_prob.append(prob_3)\n",
    "    res_prob.append(prob_4)\n",
    "    res_prob.append(prob_5)\n",
    "    res_prob.append(prob_6)\n",
    "    res_prob.append(prob_7)\n",
    "    res_prob.append(prob_8)\n",
    "    res_prob.append(prob_9)\n",
    "    return np.argmax(res_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(y_predic,y_origin):\n",
    "    temp=np.zeros(y_origin.shape[1])\n",
    "    for i in range(y_origin.shape[1]):\n",
    "        if y_predic[0][i]==y_origin[0][i]:\n",
    "            temp[i]=0\n",
    "        else:\n",
    "            temp[i]=1\n",
    "    #print(temp)\n",
    "    return (100.0 - np.mean(temp*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy Test:   9.799999999999997\n"
     ]
    }
   ],
   "source": [
    "res=[]\n",
    "for i in range(0,test_img_tr.shape[1]):\n",
    "    res.append(ten_digit(test_img_tr[:,i].reshape(test_img_tr[:,i].shape[0],1)))\n",
    "pred_test=np.asarray(res).reshape(1,np.asarray(res).shape[0])\n",
    "print(\"Accuarcy Test:  \",get_acc(pred_test,test_label_tr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
